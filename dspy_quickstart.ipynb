{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa602d14-6372-4e0a-92d8-6f7db048c3b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# DSPy Quickstart\n",
    "\n",
    "[DSPy](https://dspy-docs.vercel.app/) simplifies building language model (LM) pipelines by replacing manual prompt engineering with structured \"text transformation graphs.\" These graphs use flexible, learning modules that automate and optimize LM tasks like reasoning, retrieval, and answering complex questions. \n",
    "\n",
    "## How does it work?\n",
    "At a high level, DSPy optimizes prompts, selects the best language model, and can even fine-tune the model using training data.\n",
    "\n",
    "The process follows these three steps, common to most DSPy [optimizers](https://dspy.ai/learn/optimization/optimizers/):\n",
    "\n",
    "1. **Candidate Generation**: DSPy finds all `Predict` modules in the program and generates variations of instructions and demonstrations (e.g., examples for prompts). This step creates a set of possible candidates for the next stage.\n",
    "2. **Parameter Optimization**: DSPy then uses methods like random search, TPE, or Optuna to select the best candidate. Fine-tuning models can also be done at this stage.\n",
    "\n",
    "## This Demo\n",
    "Below we create a simple program that demonstrates the power of DSPy. We will build a text classifier leveraging OpenAI. By the end of this tutorial, we will...\n",
    "\n",
    "1. Define a [dspy.Signature](https://dspy.ai/learn/programming/signatures/) and [dspy.Module](https://dspy.ai/learn/programming/modules/) to perform text classification.\n",
    "2. Leverage [dspy.SIMBA](https://dspy.ai/api/optimizers/SIMBA/) to compile our module so it's better at classifying our text.\n",
    "3. Analyze internal steps with MLflow Tracing.\n",
    "3. Log the compiled model with MLflow.\n",
    "4. Load the logged model and perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58918566-6e93-4a2e-9a34-b0f56378885a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\benja\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Collecting openai\n",
      "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: dspy>=3.0.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: mlflow>=3.4.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (0.27.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpx<1.0.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from openai) (1.10.24)\n",
      "Requirement already satisfied: backoff>=2.2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (1.5.2)\n",
      "Requirement already satisfied: regex>=2023.10.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (2025.10.23)\n",
      "Requirement already satisfied: orjson>=3.9.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (3.11.3)\n",
      "Requirement already satisfied: optuna>=3.4.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (4.5.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (0.1.6)\n",
      "Requirement already satisfied: litellm>=1.64.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (1.78.7)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (0.52.3)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (8.5.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (5.5.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (3.1.1)\n",
      "Requirement already satisfied: rich>=13.7.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from dspy>=3.0.3) (14.1.0)\n",
      "Requirement already satisfied: gepa==0.0.7 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from gepa[dspy]==0.0.7->dspy>=3.0.3) (0.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.4-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: mlflow-skinny==3.5.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.5.1)\n",
      "Requirement already satisfied: mlflow-tracing==3.5.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.5.1)\n",
      "Requirement already satisfied: Flask-CORS<7 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (5.0.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.1.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (1.15.1)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (46.0.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.4.3)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.7.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (1.10.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (2.0.39)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow>=3.4.0) (3.0.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (8.1.8)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.70.0)\n",
      "Requirement already satisfied: fastapi<1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.118.2)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (1.37.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (5.29.3)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (1.1.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.5.3)\n",
      "Requirement already satisfied: uvicorn<1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.37.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\benja\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow>=3.4.0) (1.3.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\benja\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from cryptography<47,>=43.0.0->mlflow>=3.4.0) (2.0.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (2.38.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow>=3.4.0) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow>=3.4.0) (1.26.16)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from fastapi<1->mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.48.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=3.4.0) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=3.4.0) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=3.4.0) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=3.4.0) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow>=3.4.0) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.5.1->mlflow>=3.4.0) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (4.9)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=3.4.0) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=3.4.0) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=3.4.0) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (3.23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=3.4.0) (3.0.9)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.58b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow>=3.4.0) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.5.1->mlflow>=3.4.0) (0.4.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow>=3.4.0) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.4.0) (2.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\benja\\anaconda3\\lib\\site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow>=3.4.0) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask<4->mlflow>=3.4.0) (2.1.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from litellm>=1.64.0->dspy>=3.0.3) (0.14.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from litellm>=1.64.0->dspy>=3.0.3) (4.25.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from litellm>=1.64.0->dspy>=3.0.3) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\benja\\anaconda3\\lib\\site-packages (from litellm>=1.64.0->dspy>=3.0.3) (0.22.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3) (0.28.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\benja\\anaconda3\\lib\\site-packages (from optuna>=3.4.0->dspy>=3.0.3) (6.10.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from rich>=13.7.1->dspy>=3.0.3) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from rich>=13.7.1->dspy>=3.0.3) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\benja\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.3) (0.1.0)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.0 MB/s  0:00:00\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 28.4 MB/s  0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, pyarrow, dill, typing-inspection, pydantic-core, multiprocess, pydantic, openai, datasets\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "  Attempting uninstall: pyarrow\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "   ---------------------------------------- 0/9 [typing-extensions]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "  Attempting uninstall: dill\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "    Found existing installation: dill 0.3.6\n",
      "   ---- ----------------------------------- 1/9 [pyarrow]\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "    Uninstalling dill-0.3.6:\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "      Successfully uninstalled dill-0.3.6\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "  Attempting uninstall: typing-inspection\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "    Found existing installation: typing-inspection 0.4.1\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "    Uninstalling typing-inspection-0.4.1:\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "      Successfully uninstalled typing-inspection-0.4.1\n",
      "   -------- ------------------------------- 2/9 [dill]\n",
      "   ------------- -------------------------- 3/9 [typing-inspection]\n",
      "  Attempting uninstall: pydantic-core\n",
      "   ------------- -------------------------- 3/9 [typing-inspection]\n",
      "    Found existing installation: pydantic_core 2.33.2\n",
      "   ------------- -------------------------- 3/9 [typing-inspection]\n",
      "    Uninstalling pydantic_core-2.33.2:\n",
      "   ------------- -------------------------- 3/9 [typing-inspection]\n",
      "      Successfully uninstalled pydantic_core-2.33.2\n",
      "   ------------- -------------------------- 3/9 [typing-inspection]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ----------------- ---------------------- 4/9 [pydantic-core]\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "  Attempting uninstall: pydantic\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "    Found existing installation: pydantic 1.10.24\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "    Uninstalling pydantic-1.10.24:\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "      Successfully uninstalled pydantic-1.10.24\n",
      "   ---------------------- ----------------- 5/9 [multiprocess]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "  Attempting uninstall: openai\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "    Found existing installation: openai 2.2.0\n",
      "   -------------------------- ------------- 6/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "    Uninstalling openai-2.2.0:\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "      Successfully uninstalled openai-2.2.0\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ------------------------------- -------- 7/9 [openai]\n",
      "   ----------------------------------- ---- 8/9 [datasets]\n",
      "   ----------------------------------- ---- 8/9 [datasets]\n",
      "   ----------------------------------- ---- 8/9 [datasets]\n",
      "   ----------------------------------- ---- 8/9 [datasets]\n",
      "   ----------------------------------- ---- 8/9 [datasets]\n",
      "   ---------------------------------------- 9/9 [datasets]\n",
      "\n",
      "Successfully installed datasets-4.3.0 dill-0.4.0 multiprocess-0.70.16 openai-2.6.1 pyarrow-21.0.0 pydantic-2.12.3 pydantic-core-2.41.4 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\benja\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\benja\\anaconda3\\Lib\\site-packages\\~ydantic'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.23.4 requires anyio<4,>=3.1.0, but you have anyio 4.11.0 which is incompatible.\n",
      "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 0.2.43 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets openai \"dspy>=3.0.3\" \"mlflow>=3.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd9e460-4c9c-4508-8801-6f29fcf2c8d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c27ec364-1195-447d-a9d5-f38defa6652e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set Up LLM\n",
    "\n",
    "After installing the relevant dependencies, let's set up access to an OpenAI LLM. Here, will leverage OpenAI's `gpt-4o-mini` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key to the environment variable. You can also pass the token to dspy.LM()\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3232fb03-f4be-490f-9179-0f2b71129196",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Define your model. We will use OpenAI for simplicity\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# Note that an OPENAI_API_KEY environment must be present. You can also pass the token to dspy.LM()\n",
    "lm = dspy.LM(\n",
    "    model=f\"openai/{model_name}\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.1,\n",
    ")\n",
    "dspy.settings.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLflow Experiment\n",
    "\n",
    "Create a new MLflow Experiment to track your DSPy models, metrics, parameters, and traces in one place. Although there is already a \"default\" experiment created in your workspace, it is highly recommended to create one for different tasks to organize experiment artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "2025/10/25 16:46:02 INFO mlflow.tracking.fluent: Experiment with name 'DSPy Quickstart' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/SMU_work/Year%203%20Sem%201/Gen%20AI/Project/ANEETAA/mlruns/482380963199463283', creation_time=1761381962226, experiment_id='482380963199463283', last_update_time=1761381962226, lifecycle_stage='active', name='DSPy Quickstart', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"DSPy Quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn on Auto Tracing with MLflow\n",
    "\n",
    "[MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html) is a powerful observability tool for monitoring and debugging what happens inside your DSPy modules, helping you identify potential bottlenecks or issues quickly. To enable DSPy tracing, you just need to call `mlflow.dspy.autolog` and that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fde40f-650a-4090-9791-120dd954cd36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set Up Data\n",
    "\n",
    "Next, we will download the [Reuters 21578](https://huggingface.co/datasets/yangwang825/reuters-21578) dataset from Huggingface. We also write a utility to ensure that our train/test split has the same labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd53a405-1685-4e2f-86c5-8f3f570828c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67124fb03741ac9c29480263eecbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benja\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\benja\\.cache\\huggingface\\hub\\datasets--yangwang825--reuters-21578. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89401f39352d472bb784139cdcd8bf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d87d91592341e4acc9bec09d628ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31f920c3e804658ac84580f75da9d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6140c8cc611a4109a500996867b0a41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 8\n",
      "Train labels: {'grain', 'ship', 'crude', 'earn', 'trade', 'acq', 'money-fx', 'interest'}\n",
      "Example({'text': 'spain deregulates bank deposit interest rates spain s finance ministry deregulated bank deposit rates in an effort to raise competition among banks and bring legislation into line with the european community ec a ministry spokesman said the measure was published today in the official state gazette it takes effect tomorrow and lifts restrictions on rates now limited to six pct on deposits of up to days the government also enacted a decree cutting to one pct from pct the proportion of total assets which banks must lend at favourable rates to industries classified of public interest some bankers expect the deregulation of rates to result in a pct drop in profits this year secretary of state for the economy guillermo de la dehesa told reuters in a recent interview the reduction in fixed asset investments would offset losses from the rate liberalisation reuter', 'label': 'interest'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from dspy.datasets.dataset import Dataset\n",
    "\n",
    "\n",
    "def read_data_and_subset_to_categories() -> tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read the reuters-21578 dataset. Docs can be found in the url below:\n",
    "    https://huggingface.co/datasets/yangwang825/reuters-21578\n",
    "    \"\"\"\n",
    "\n",
    "    # Read train/test split\n",
    "    dataset = load_dataset(\"yangwang825/reuters-21578\")\n",
    "    train = pd.DataFrame(dataset[\"train\"])\n",
    "    test = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "    # Clean the labels\n",
    "    label_map = {\n",
    "        0: \"acq\",\n",
    "        1: \"crude\",\n",
    "        2: \"earn\",\n",
    "        3: \"grain\",\n",
    "        4: \"interest\",\n",
    "        5: \"money-fx\",\n",
    "        6: \"ship\",\n",
    "        7: \"trade\",\n",
    "    }\n",
    "\n",
    "    train[\"label\"] = train[\"label\"].map(label_map)\n",
    "    test[\"label\"] = test[\"label\"].map(label_map)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, n_train_per_label: int = 20, n_test_per_label: int = 10, *args, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_train_per_label = n_train_per_label\n",
    "        self.n_test_per_label = n_test_per_label\n",
    "\n",
    "        self._create_train_test_split_and_ensure_labels()\n",
    "\n",
    "    def _create_train_test_split_and_ensure_labels(self) -> None:\n",
    "        \"\"\"Perform a train/test split that ensure labels in `dev` are also in `train`.\"\"\"\n",
    "        # Read the data\n",
    "        train_df, test_df = read_data_and_subset_to_categories()\n",
    "\n",
    "        # Sample for each label\n",
    "        train_samples_df = pd.concat(\n",
    "            [group.sample(n=self.n_train_per_label) for _, group in train_df.groupby(\"label\")]\n",
    "        )\n",
    "        test_samples_df = pd.concat(\n",
    "            [group.sample(n=self.n_test_per_label) for _, group in test_df.groupby(\"label\")]\n",
    "        )\n",
    "\n",
    "        # Set DSPy class variables\n",
    "        self._train = train_samples_df.to_dict(orient=\"records\")\n",
    "        self._dev = test_samples_df.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# Limit to a small dataset to showcase the value of bootstrapping\n",
    "dataset = CSVDataset(n_train_per_label=3, n_test_per_label=1)\n",
    "\n",
    "# Create train and test sets containing DSPy\n",
    "# Note that we must specify the expected input value name\n",
    "train_dataset = [example.with_inputs(\"text\") for example in dataset.train]\n",
    "test_dataset = [example.with_inputs(\"text\") for example in dataset.dev]\n",
    "unique_train_labels = {example.label for example in dataset.train}\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n",
    "print(f\"Train labels: {unique_train_labels}\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a683b83-6acc-4fdf-846f-bd81cadda53b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set up DSPy Signature and Module\n",
    "\n",
    "Finally, we will define our task: text classification.\n",
    "\n",
    "There are a variety of ways you can provide guidelines to DSPy signature behavior. Currently, DSPy allows users to specify:\n",
    "\n",
    "1. A high-level goal via the class docstring.\n",
    "2. A set of input fields, with optional metadata.\n",
    "3. A set of output fields with optional metadata.\n",
    "\n",
    "DSPy will then leverage this information to inform optimization. \n",
    "\n",
    "In the below example, note that we simply provide the expected labels to `output` field in the `TextClassificationSignature` class. From this initial state, we'll look to use DSPy to learn to improve our classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0743c63-c679-4114-b7b1-bed4aeb918cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TextClassificationSignature(dspy.Signature):\n",
    "    text = dspy.InputField()\n",
    "    label = dspy.OutputField(\n",
    "        desc=f\"Label of predicted class. Possible labels are {unique_train_labels}\"\n",
    "    )\n",
    "\n",
    "\n",
    "class TextClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_classification = dspy.Predict(TextClassificationSignature)\n",
    "\n",
    "    def forward(self, text: str):\n",
    "        return self.generate_classification(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d93df5c-25d7-460d-a803-0e5469f3bbad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89741fa-2698-4409-b290-f5f5652f7d66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Hello World\n",
    "Let's demonstrate predicting via the DSPy module and associated signature. The program has correctly learned our labels from the signature `desc` field and generates reasonable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4da1ad9-7173-4d1b-ab53-346e9c49fbbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/25 16:46:23 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "litellm.BadRequestError: OpenAIException - You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:745\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[0m\n\u001b[0;32m    744\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 745\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:673\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[0m\n\u001b[0;32m    659\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mpre_call(\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m    661\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_client\u001b[38;5;241m.\u001b[39mapi_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m     },\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    670\u001b[0m (\n\u001b[0;32m    671\u001b[0m     headers,\n\u001b[0;32m    672\u001b[0m     response,\n\u001b[1;32m--> 673\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_sync_openai_chat_completion_request(\n\u001b[0;32m    674\u001b[0m     openai_client\u001b[38;5;241m=\u001b[39mopenai_client,\n\u001b[0;32m    675\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    677\u001b[0m     logging_obj\u001b[38;5;241m=\u001b[39mlogging_obj,\n\u001b[0;32m    678\u001b[0m )\n\u001b[0;32m    680\u001b[0m logging_obj\u001b[38;5;241m.\u001b[39mmodel_call_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m headers\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\litellm_core_utils\\logging_utils.py:237\u001b[0m, in \u001b[0;36mtrack_llm_api_timing.<locals>.decorator.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:489\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:471\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.make_sync_openai_chat_completion_request\u001b[1;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m     raw_response \u001b[38;5;241m=\u001b[39m openai_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mwith_raw_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    472\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    473\u001b[0m     )\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\openai\\_legacy_response.py:364\u001b[0m, in \u001b[0;36mto_raw_response_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m extra_headers\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1156\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1155\u001b[0m validate_response_format(response_format)\n\u001b[1;32m-> 1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1158\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m   1159\u001b[0m         {\n\u001b[0;32m   1160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1163\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1165\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1166\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1167\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1168\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1169\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1170\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1171\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1173\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[0;32m   1177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[0;32m   1180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1182\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1183\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1187\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1191\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[0;32m   1193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m   1194\u001b[0m         },\n\u001b[0;32m   1195\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m   1198\u001b[0m     ),\n\u001b[0;32m   1199\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1200\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1201\u001b[0m     ),\n\u001b[0;32m   1202\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1203\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1204\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m   1205\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m )\n\u001b[1;32m-> 1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\main.py:2137\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[0m\n\u001b[0;32m   2131\u001b[0m     logging\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[0;32m   2132\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   2133\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   2134\u001b[0m         original_response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   2135\u001b[0m         additional_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: headers},\n\u001b[0;32m   2136\u001b[0m     )\n\u001b[1;32m-> 2137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optional_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2140\u001b[0m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\main.py:2109\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[0m\n\u001b[0;32m   2108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2109\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai_chat_completions\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[0;32m   2110\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   2111\u001b[0m             messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   2112\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   2113\u001b[0m             model_response\u001b[38;5;241m=\u001b[39mmodel_response,\n\u001b[0;32m   2114\u001b[0m             print_verbose\u001b[38;5;241m=\u001b[39mprint_verbose,\n\u001b[0;32m   2115\u001b[0m             api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[0;32m   2116\u001b[0m             api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[0;32m   2117\u001b[0m             acompletion\u001b[38;5;241m=\u001b[39macompletion,\n\u001b[0;32m   2118\u001b[0m             logging_obj\u001b[38;5;241m=\u001b[39mlogging,\n\u001b[0;32m   2119\u001b[0m             optional_params\u001b[38;5;241m=\u001b[39moptional_params,\n\u001b[0;32m   2120\u001b[0m             litellm_params\u001b[38;5;241m=\u001b[39mlitellm_params,\n\u001b[0;32m   2121\u001b[0m             logger_fn\u001b[38;5;241m=\u001b[39mlogger_fn,\n\u001b[0;32m   2122\u001b[0m             timeout\u001b[38;5;241m=\u001b[39mtimeout,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2123\u001b[0m             custom_prompt_dict\u001b[38;5;241m=\u001b[39mcustom_prompt_dict,\n\u001b[0;32m   2124\u001b[0m             client\u001b[38;5;241m=\u001b[39mclient,  \u001b[38;5;66;03m# pass AsyncOpenAI, OpenAI client\u001b[39;00m\n\u001b[0;32m   2125\u001b[0m             organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[0;32m   2126\u001b[0m             custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m   2127\u001b[0m             shared_session\u001b[38;5;241m=\u001b[39mshared_session,\n\u001b[0;32m   2128\u001b[0m         )\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2130\u001b[0m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\llms\\openai\\openai.py:756\u001b[0m, in \u001b[0;36mOpenAIChatCompletion.completion\u001b[1;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[0m\n\u001b[0;32m    755\u001b[0m     error_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 756\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    757\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[0;32m    758\u001b[0m     message\u001b[38;5;241m=\u001b[39merror_text,\n\u001b[0;32m    759\u001b[0m     headers\u001b[38;5;241m=\u001b[39merror_headers,\n\u001b[0;32m    760\u001b[0m     body\u001b[38;5;241m=\u001b[39merror_body,\n\u001b[0;32m    761\u001b[0m )\n",
      "\u001b[1;31mOpenAIError\u001b[0m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\utils.py:1244\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m-> 1244\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1245\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\main.py:3733\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[0m\n\u001b[0;32m   3731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3732\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[1;32m-> 3733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[0;32m   3734\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   3735\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m   3736\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[0;32m   3737\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   3738\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   3739\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2273\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m   2272\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:392\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[0;32m    393\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    394\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m    395\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    396\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    397\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[0;32m    398\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    399\u001b[0m     )\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeb server is returning an unknown error\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server had an error processing your request.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    403\u001b[0m ):\n",
      "\u001b[1;31mBadRequestError\u001b[0m: litellm.BadRequestError: OpenAIException - You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m text_classifier \u001b[38;5;241m=\u001b[39m TextClassifier()\n\u001b[0;32m      4\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am interested in space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_classifier(text\u001b[38;5;241m=\u001b[39mmessage))\n\u001b[0;32m      7\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI enjoy ice skating\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_classifier(text\u001b[38;5;241m=\u001b[39mmessage))\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:343\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    342\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     ACTIVE_CALL_ID\u001b[38;5;241m.\u001b[39mset(parent_call_id)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:339\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     results \u001b[38;5;241m=\u001b[39m fn(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\primitives\\module.py:78\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     output\u001b[38;5;241m.\u001b[39mset_lm_usage(usage_tracker\u001b[38;5;241m.\u001b[39mget_total_tokens())\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mTextClassifier.forward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_classification(text\u001b[38;5;241m=\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\predict\\predict.py:103\u001b[0m, in \u001b[0;36mPredict.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_positional_args_error_message())\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:343\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    342\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     ACTIVE_CALL_ID\u001b[38;5;241m.\u001b[39mset(parent_call_id)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:339\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     results \u001b[38;5;241m=\u001b[39m fn(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\primitives\\module.py:78\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     output\u001b[38;5;241m.\u001b[39mset_lm_usage(usage_tracker\u001b[38;5;241m.\u001b[39mget_total_tokens())\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\predict\\predict.py:192\u001b[0m, in \u001b[0;36mPredict.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcontext(send_stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 192\u001b[0m         completions \u001b[38;5;241m=\u001b[39m adapter(lm, lm_kwargs\u001b[38;5;241m=\u001b[39mconfig, signature\u001b[38;5;241m=\u001b[39msignature, demos\u001b[38;5;241m=\u001b[39mdemos, inputs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_postprocess(completions, signature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:47\u001b[0m, in \u001b[0;36mChatAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\adapters\\json_adapter.py:82\u001b[0m, in \u001b[0;36mJSONAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[0;32m     80\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to use structured output format, falling back to JSON mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m lm_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(lm, lm_kwargs, signature, demos, inputs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:46\u001b[0m, in \u001b[0;36mChatAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdspy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONAdapter\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ContextWindowExceededError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, JSONAdapter):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# On context window exceeded error or already using JSONAdapter, we don't want to retry with a different\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# adapter.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\adapters\\chat_adapter.py:38\u001b[0m, in \u001b[0;36mChatAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     31\u001b[0m     lm: LM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(lm, lm_kwargs, signature, demos, inputs)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# fallback to JSONAdapter\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdspy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_adapter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONAdapter\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\adapters\\base.py:127\u001b[0m, in \u001b[0;36mAdapter.__call__\u001b[1;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[0;32m    124\u001b[0m processed_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_preprocess(lm, lm_kwargs, signature, inputs)\n\u001b[0;32m    125\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(processed_signature, demos, inputs)\n\u001b[1;32m--> 127\u001b[0m outputs \u001b[38;5;241m=\u001b[39m lm(messages\u001b[38;5;241m=\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlm_kwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_postprocess(processed_signature, signature, outputs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:343\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    342\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     ACTIVE_CALL_ID\u001b[38;5;241m.\u001b[39mset(parent_call_id)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\utils\\callback.py:339\u001b[0m, in \u001b[0;36mwith_callbacks.<locals>.sync_wrapper\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     results \u001b[38;5;241m=\u001b[39m fn(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\clients\\base_lm.py:85\u001b[0m, in \u001b[0;36mBaseLM.__call__\u001b[1;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 85\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(prompt\u001b[38;5;241m=\u001b[39mprompt, messages\u001b[38;5;241m=\u001b[39mmessages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_lm_response(response, prompt, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\clients\\lm.py:147\u001b[0m, in \u001b[0;36mLM.forward\u001b[1;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m     completion \u001b[38;5;241m=\u001b[39m litellm_responses_completion\n\u001b[0;32m    145\u001b[0m completion, litellm_cache_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cached_completion_fn(completion, cache)\n\u001b[1;32m--> 147\u001b[0m results \u001b[38;5;241m=\u001b[39m completion(\n\u001b[0;32m    148\u001b[0m     request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, messages\u001b[38;5;241m=\u001b[39mmessages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    149\u001b[0m     num_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_retries,\n\u001b[0;32m    150\u001b[0m     cache\u001b[38;5;241m=\u001b[39mlitellm_cache_args,\n\u001b[0;32m    151\u001b[0m )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_truncation(results)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_hit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m dspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39musage_tracker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\clients\\cache.py:235\u001b[0m, in \u001b[0;36mrequest_cache.<locals>.decorator.<locals>.sync_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Otherwise, compute and store the result\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Make a copy of the original request in case it's modified in place, e.g., deleting some fields\u001b[39;00m\n\u001b[0;32m    234\u001b[0m original_request \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(modified_request)\n\u001b[1;32m--> 235\u001b[0m result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# `enable_memory_cache` can be provided at call time to avoid indefinite growth.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m cache\u001b[38;5;241m.\u001b[39mput(original_request, result, ignored_args_for_cache_key, enable_memory_cache)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\dspy\\clients\\lm.py:336\u001b[0m, in \u001b[0;36mlitellm_completion\u001b[1;34m(request, num_retries, cache)\u001b[0m\n\u001b[0;32m    334\u001b[0m stream_completion \u001b[38;5;241m=\u001b[39m _get_stream_completion_fn(request, cache, sync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_completion \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mcompletion(\n\u001b[0;32m    337\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m    338\u001b[0m         num_retries\u001b[38;5;241m=\u001b[39mnum_retries,\n\u001b[0;32m    339\u001b[0m         retry_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexponential_backoff_retry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest,\n\u001b[0;32m    341\u001b[0m     )\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream_completion()\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\utils.py:1351\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1346\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mAPIError)\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mTimeout)\n\u001b[0;32m   1348\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, openai\u001b[38;5;241m.\u001b[39mAPIConnectionError)\n\u001b[0;32m   1349\u001b[0m     ):\n\u001b[0;32m   1350\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_retries\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mcompletion_with_retries(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1353\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(e, litellm\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mContextWindowExceededError)\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m context_window_fallback_dict\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m context_window_fallback_dict\n\u001b[0;32m   1356\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_litellm_router_call\n\u001b[0;32m   1357\u001b[0m ):\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\main.py:3771\u001b[0m, in \u001b[0;36mcompletion_with_retries\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3768\u001b[0m     retryer \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\n\u001b[0;32m   3769\u001b[0m         stop\u001b[38;5;241m=\u001b[39mtenacity\u001b[38;5;241m.\u001b[39mstop_after_attempt(num_retries), reraise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m     )\n\u001b[1;32m-> 3771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retryer(original_function, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m action(retry_state)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\utils.py:1371\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[0;32m   1368\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[0;32m   1369\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[0;32m   1370\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[1;32m-> 1371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\utils.py:1244\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m-> 1244\u001b[0m result \u001b[38;5;241m=\u001b[39m original_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1245\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[0;32m   1247\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   1248\u001b[0m     call_type\u001b[38;5;241m=\u001b[39mcall_type,\n\u001b[0;32m   1249\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\main.py:3733\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[0m\n\u001b[0;32m   3730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m   3731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   3732\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[1;32m-> 3733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_type(\n\u001b[0;32m   3734\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   3735\u001b[0m         custom_llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m   3736\u001b[0m         original_exception\u001b[38;5;241m=\u001b[39me,\n\u001b[0;32m   3737\u001b[0m         completion_kwargs\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   3738\u001b[0m         extra_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   3739\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:2273\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[0;32m   2272\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[1;32mc:\\Users\\benja\\anaconda3\\Lib\\site-packages\\litellm\\litellm_core_utils\\exception_mapping_utils.py:392\u001b[0m, in \u001b[0;36mexception_type\u001b[1;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid_request_error\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect API key provided\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    390\u001b[0m ):\n\u001b[0;32m    391\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n\u001b[0;32m    393\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    394\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[0;32m    395\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    396\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    397\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[0;32m    398\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    399\u001b[0m     )\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeb server is returning an unknown error\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server had an error processing your request.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[0;32m    403\u001b[0m ):\n\u001b[0;32m    404\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: litellm.BadRequestError: OpenAIException - You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "# Initilize our impact_improvement class\n",
    "text_classifier = TextClassifier()\n",
    "\n",
    "message = \"I am interested in space\"\n",
    "print(text_classifier(text=message))\n",
    "\n",
    "message = \"I enjoy ice skating\"\n",
    "print(text_classifier(text=message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Traces\n",
    "\n",
    "1. Open the MLflow UI and select the `\"DSPy Quickstart\"` experiment.\n",
    "2. Go to the `\"Traces\"` tab to view the generated traces.\n",
    "\n",
    "Now, you can observe how DSPy translates your query and interacts with the LLM. This feature is extremely valuable for debugging, iteratively refining components within your system, and monitoring models in production. While the module in this tutorial is relatively simple, the tracing feature becomes even more powerful as your model grows in complexity.\n",
    "\n",
    "![MLflow DSPy Trace](/images/llms/dspy/dspy-trace.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b064a99e-027a-4854-873b-5347d901de46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Compilation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a82d466-40f7-411a-a029-dcadb4629391",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "To train, we will leverage [SIMBA](https://dspy.ai/api/optimizers/SIMBA/), an optimizer that will take bootstrap samples from our training set and leverage a random search strategy to optimize our predictive accuracy.\n",
    "\n",
    "Note that in the below example, we leverage a simple metric definition of exact match, as defined in `validate_classification`, but [dspy.Metrics](https://dspy.ai/learn/evaluation/metrics/) can contain complex and LM-based logic to properly evaluate our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7d41f13-ef79-45bf-90fa-2abee39c35ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dspy import SIMBA\n",
    "\n",
    "\n",
    "def validate_classification(example, prediction, trace=None) -> bool:\n",
    "    return example.label == prediction.label\n",
    "\n",
    "\n",
    "optimizer = SIMBA(\n",
    "    metric=validate_classification,\n",
    "    max_demos=2,\n",
    "    bsize=12,\n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "compiled_pe = optimizer.compile(TextClassifier(), trainset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f09466f-b929-4ebf-adfd-01c9387d3c8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Compare Pre/Post Compiled Accuracy\n",
    "\n",
    "Finally, let's explore how well our trained model can predict on unseen test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c075af7e-b15d-4adb-ab2a-e65bbdc38069",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompiled accuracy: 0.875\n",
      "Compiled accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(classifier, test_data: pd.DataFrame = test_dataset) -> float:\n",
    "    residuals = []\n",
    "    predictions = []\n",
    "    for example in test_data:\n",
    "        prediction = classifier(text=example[\"text\"])\n",
    "        residuals.append(int(validate_classification(example, prediction)))\n",
    "        predictions.append(prediction)\n",
    "    return residuals, predictions\n",
    "\n",
    "\n",
    "uncompiled_residuals, uncompiled_predictions = check_accuracy(TextClassifier())\n",
    "print(f\"Uncompiled accuracy: {np.mean(uncompiled_residuals)}\")\n",
    "\n",
    "compiled_residuals, compiled_predictions = check_accuracy(compiled_pe)\n",
    "print(f\"Compiled accuracy: {np.mean(compiled_residuals)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0964ae5f-6dfe-4b52-8a91-b91d45f69b82",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As shown above, our compiled accuracy is non-zero - our base LLM inferred meaning of the classification labels simply via our initial prompt. However, with DSPy training, the prompts, demonstrations, and input/output signatures have been updated to give our model to 100% accuracy on unseen data. That's a gain of 12 percentage points!\n",
    "\n",
    "Let's take a look at each prediction in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9228b66-864b-49fb-838d-33c12e2ff8b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction:    money-fx\n",
      "Correct prediction:      crude\n",
      "Correct prediction:      money-fx\n",
      "Correct prediction:      earn\n",
      "Incorrect prediction:    interest\n",
      "Correct prediction:      grain\n",
      "Correct prediction:      trade\n",
      "Incorrect prediction:    trade\n"
     ]
    }
   ],
   "source": [
    "for uncompiled_residual, uncompiled_prediction in zip(uncompiled_residuals, uncompiled_predictions):\n",
    "    is_correct = \"Correct\" if bool(uncompiled_residual) else \"Incorrect\"\n",
    "    prediction = uncompiled_prediction.label\n",
    "    print(f\"{is_correct} prediction: {' ' * (12 - len(is_correct))}{prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93c1b68-a95e-436e-9c0d-54b2b3e34f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction:      interest\n",
      "Correct prediction:      crude\n",
      "Correct prediction:      money-fx\n",
      "Correct prediction:      earn\n",
      "Correct prediction:      acq\n",
      "Correct prediction:      grain\n",
      "Correct prediction:      trade\n",
      "Correct prediction:      ship\n"
     ]
    }
   ],
   "source": [
    "for compiled_residual, compiled_prediction in zip(compiled_residuals, compiled_predictions):\n",
    "    is_correct = \"Correct\" if bool(compiled_residual) else \"Incorrect\"\n",
    "    prediction = compiled_prediction.label\n",
    "    print(f\"{is_correct} prediction: {' ' * (12 - len(is_correct))}{prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73351663-ed84-4e29-8bf5-61fbf94da937",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Log and Load the Model with MLflow\n",
    "\n",
    "Now that we have a compiled model with higher classification accuracy, let's leverage MLflow to log this model and load it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94969489f0444d3a919ccf11f0bc4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.dspy.log_model(\n",
    "        compiled_pe,\n",
    "        name=\"model\",\n",
    "        input_example=\"what is 2 + 2?\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the MLflow UI again and check the complied model is recorded to a new MLflow Run. Now you can load the model back for inference using `mlflow.dspy.load_model` or `mlflow.pyfunc.load_model`.\n",
    "\n",
    " MLflow will remember the environment configuration stored in `dspy.settings`, such as the language model (LM) used during the experiment. This ensures excellent reproducibility for your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============Input Text============\n",
      "Text: top discount rate at u k bill tender rises to pct\n",
      "\n",
      "--------------Original DSPy Prediction------------\n",
      "interest\n",
      "\n",
      "--------------Loaded DSPy Prediction------------\n",
      "interest\n",
      "\n",
      "--------------PyFunc Prediction------------\n",
      "interest\n"
     ]
    }
   ],
   "source": [
    "# Define input text\n",
    "print(\"\\n==============Input Text============\")\n",
    "text = test_dataset[0][\"text\"]\n",
    "print(f\"Text: {text}\")\n",
    "\n",
    "# Inference with original DSPy object\n",
    "print(\"\\n--------------Original DSPy Prediction------------\")\n",
    "print(compiled_pe(text=text).label)\n",
    "\n",
    "# Inference with loaded DSPy object\n",
    "print(\"\\n--------------Loaded DSPy Prediction------------\")\n",
    "loaded_model_dspy = mlflow.dspy.load_model(model_info.model_uri)\n",
    "print(loaded_model_dspy(text=text).label)\n",
    "\n",
    "# Inference with MLflow PyFunc API\n",
    "loaded_model_pyfunc = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "print(\"\\n--------------PyFunc Prediction------------\")\n",
    "print(loaded_model_pyfunc.predict(text)[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09199461-878a-4b9f-9eb0-8803775a6cc5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "This example demonstrates how DSPy works. Below are some potential extensions for improving this project, both with DSPy and MLflow.\n",
    "\n",
    "### DSPy\n",
    "* Use real-world data for the classifier.\n",
    "* Experiment with different optimizers.\n",
    "* For more in-depth examples, check out the [tutorials](https://dspy.ai/tutorials/) and [documentation](https://dspy.ai/learn/).\n",
    "\n",
    "### MLflow\n",
    "* Deploy the model using MLflow serving.\n",
    "* Use MLflow to experiment with various optimization strategies.\n",
    "* Track your DSPy experiments using [DSPy Optimizer Autologging](https://mlflow.org/docs/latest/genai/flavors/dspy/optimizer/).\n",
    "\n",
    "Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Simple DSPy Classifier OSS",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
